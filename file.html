<div role="main">
    <div class="box py-3 generalbox center clearfix">
        <div class="no-overflow">
            <h2 align="center"> <em> "The Freshman Problem - Where is my next class?" </em> </h2>
            <p align="center"> Final project by </p>
            <p align="center"> <b> Ron Haikin, Roy Amoyal and Omri Hirsch </b> </p>
            <p align="center"> <a href="mailto:ronkh@post.bgu.ac.il"> ronkh@post.bgu.ac.il</a>,
                               <a href="mailto:amoyalr@post.bgu.ac.il"> amoyalr@post.bgu.ac.il</a>,
                               <a href="mailto:omrihir@post.bgu.ac.il"> omrihir@post.bgu.ac.il</a> </p>

            <hr>

            <h2 align="left"> Introduction </h2>
            <p align="justify">
                Imagine being a freshman at Ben-Gurion University, stepping onto campus with excitement and anticipation, <br>
                only to find yourself lost in a maze of buildings, unsure of where your next class is located. <br>
                It's a common scenario – asking strangers for directions, rushing through unfamiliar corridors, risking being late for class. <br>
                <br>
                In addressing this challenge, we embarked on a mission driven by empathy and innovation. <br>
                What if we could harness the power of computer vision to guide these students seamlessly through their campus journey? <br>
                Thus, our project was born, with a vision to empower students to effortlessly navigate their academic environment using nothing but their smartphone's camera. <br>
                <br>
                Our goal was clear: to eliminate the confusion of building numbers and convoluted navigation instructions. <br>
                Instead, we sought to provide a solution that intuitively understands the student's location within Ben-Gurion University, <br>
                allowing for swift and precise guidance to their destination. <br>
                <br>
                Central to our endeavor was the formidable task of localization – the ability to pinpoint the student's exact whereabouts with a single snapshot from their camera. <br>
                This one-shot image became the cornerstone of our approach, unlocking the potential to revolutionize campus navigation for students.
            </p>

            <h2 align="left"> Approach and Method</h2>
            <p align="justify">
                <h3 align="left"> Algorithmic:</h3>

                Our strategy for addressing the location detection challenge revolved around employing sophisticated methods for feature extraction and matching within images.<br>
                <br>
                Initiating our process, we recognized the necessity of assembling a comprehensive repository of images <br>
                capturing key landmarks and areas across the university campus.<br>
                From this repository, we a like database and precomputed the pertinent features.<br>
                <br>
                In determining the most suitable algorithms, we conducted an extensive exploration of classical approaches such as <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"> SIFT</a>, <a href="https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html"> ORB</a>, and <a href="https://docs.opencv.org/3.4/db/d70/tutorial_akaze_matching.html"> AKAZE</a>, all Gradient based.<br>
                Following thorough evaluation, <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"> SIFT</a> emerged as the optimal choice due to its proficiency in identifying key points and generating distinctive descriptors akin to individualized fingerprints.<br>
                <br>
                <h4 align=""left"> SIFT:</h4>
                There are some corner detectors like Harris etc. <br>
                They are rotation-invariant, which means, even if the image is rotated, we can find the same corners. <br>
                It is obvious because corners remain corners in rotated image also. <br>
                But what about scaling? A corner may not be a corner if the image is scaled. <br>
                For example, check the simple image below. <br>
                A corner in a small image within a small window is flat when it is zoomed in the same window. <br>
                So Harris corner detector and others are not scale invariant. <br>
                <image src="https://docs.opencv.org/4.x/sift_scale_invariant.jpg" width="200" height="120"></image> <br>
                Here comes into play SIFT algorithm: <br>
                <br>
                SIFT is a computer vision algorithm used for detecting and describing local features in images. <br>
                SIFT is rotational invariant, as also, scale invariant. <br>
                It's widely used for tasks like object recognition, image stitching, and matching. <br>
                <image src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*bPN9KN1Y7Lkl8_8wfNtQgA.png" width="400" height="300"></image>
                <br>
                
                However, in practical application, we encountered limitations with <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"> SIFT</a>'s feature matching capabilities.<br>
                To overcome this obstacle, we turned to deep learning techniques, specifically leveraging the <a href="https://github.com/cvg/LightGlue">"Light Glue"</a> neural network.<br>
                <h4 align=""left"> Light Glue:</h4>
                This is an advanced model facilitated more accurate and robust feature matching between images, thereby enhancing the efficacy of our solution.<br>
                Light Glue is a lightweight feature matcher with high accuracy and blazing fast inference.<br>
                It takes as input a set of keypoints and descriptors for each image and returns the indices of corresponding points.<br>
                The architecture is based on adaptive pruning techniques, in both network width and depth <a href="https://arxiv.org/pdf/2306.13643">check out the paper for more details.</a>
                <br>
                <image src="https://github.com/cvg/LightGlue/raw/main/assets/easy_hard.jpg" width="400" height="300"></image>
                <h4 align=""left"> Finding the best matching Building - KNN algorithm:</h4>
                Subsequently, the task of accurately identifying the depicted building within a user's image prompted the utilization of the K-Nearest Neighbors (<a href="https://he.wikipedia.org/wiki/%D7%90%D7%9C%D7%92%D7%95%D7%A8%D7%99%D7%AA%D7%9D_%D7%A9%D7%9B%D7%9F_%D7%A7%D7%A8%D7%95%D7%91"> KNN</a>) algorithm, with a parameter value (k) of 5, for efficient classification.<br>
                <br>
                <image src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/330px-KnnClassification.svg.png" width="200" height="200"></image>
                <br>
                <h3 align="left"> UI and App Development:</h3>
                <h4 align="left"> Streamlit.io:</h4>
                <image src="https://streamlit.io/images/brand/streamlit-logo-primary-colormark-darktext.png" width="80" height="60"></image> <br>
                <br>
                In the realm of user interface design, we've chosen <a href="https://streamlit.io/"> Streamlit.io</a> as our cornerstone development platform for web and mobile applications, captivated by its intuitive Python-based framework.<br>
                It offers an effortless experience for both phone and computer use, coupled with easy programming capabilities.<br>
                With <a href="https://streamlit.io/"> Streamlit.io</a>, users can enjoy seamless interactions, upload images effortlessly, monitor progress with informative progress bars, utilize GPU acceleration for swift computations, and leverage Google Maps integration for navigation assistance.<br>
                Deployed to a Streamlit-hosted server, <a href="https://the-lost-student-app.streamlit.app/">our application</a> ensures widespread accessibility and effortless utilization, offering streamlined solutions for campus navigation.<br>
            </p>

            <h3 align="left"> Results</h3>
            <p align="justify">
                Describe and show here your results. Using images/videos is particularly welcome.
            </p>

            <h3 align="left"> Project's Video</h3>
            <p align="justify">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/LYcXAEZfQFY?enablejsapi=1"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen="" id="annoto_player_id_pfi78r" data-gtm-yt-inspected-7="true"
                    title="Ben-Gurion University of the Negev 2019" class="annoto-player-element"></iframe>
            <div class="annoto-timeline-dock" style="float: none; height: 48px; width: 560px;"><nn-timeline
                    style="--nn-zindex: 100; display: block; width: 100%;"> <nnc-timeline ref="timelineElement"
                        chart-series.bind="chartSeries" chart-resolution.bind="resolution" chart-hiding.bind="isOverlay"
                        chart-height.bind="chartHeight" pd.bind="pd" pp.bind="pp"
                        nncevent.trigger="timelineEventHandle($event)"
                        class="au-target annoto nnc nnc-timeline hydrated" au-target-id="361" aria-hidden="true"
                        tabindex="-1"><!----> <!--anchor--> <!--anchor-->
                        <div class="nnc-timeline-chart-container"></div>
                        <div class="nnc-timeline-cta-container"><nnc-timeline-cta ref="ctaElement" slot="cta"
                                pd.bind="pd" cta-list.bind="ctaList"
                                tooltip-position.bind="isOverlay ? 'top' : 'bottom'"
                                class="au-target nnc nnc-timeline-cta hydrated"
                                au-target-id="362"><nnc-timeline-icons-loader class="hydrated"
                                    style="display: none;"><nnc-icon role="img" class="nnc nnc-icon hydrated"
                                        aria-label="choice sign" name="choice-sign"></nnc-icon><nnc-icon role="img"
                                        class="nnc nnc-icon hydrated" aria-label="radio group"
                                        name="radio-group"></nnc-icon><nnc-icon role="img" class="nnc nnc-icon hydrated"
                                        aria-label="check list"
                                        name="check-list"></nnc-icon></nnc-timeline-icons-loader>
                                <div class="nnc-timeline-cta-tooltips"></div>
                            </nnc-timeline-cta></div>
                        <div class="nnc-timeline-progressbar-container"><nnc-timeline-progress-bar slot="progressbar"
                                pd.bind="pd" pp.bind="pp" class="au-target nnc nnc-timeline-progress-bar hydrated"
                                au-target-id="364"></nnc-timeline-progress-bar></div>
                    </nnc-timeline><!--anchor--> </nn-timeline></div>
            </p>

            <h3 align="left"> Conclusions</h3>
            <p align="justify">
                Discuss the results vis-a-vis your goals and make conclusions.
            </p>

            <h3 align="left"> Additional Information</h3>
            <p align="justify">
            </p>
            <ul>
                <li> Full project report (<a href="">PDF - TODO</a>).
                </li>
                <li> Oral presentation slides (<a href="">ppt - TODO</a>
                    , <a href="">PDF - TODO</a>).
                </li>
                <li> Project's video file (<a href="">TODO</a>).
                </li>
                <li> <a href="https://the-lost-student-app.streamlit.app/">Link to our App</a>
                </li>
                <li> <a href="https://github.com/RoyAmoyal/The_Lost_Student_App">Github - Downloadable source code</a>.
                </li>
                
            </ul>
            <p></p>

            <h3 align="left"> References </h3>
            <p align="justify">
                <a href ="https://arxiv.org/pdf/2306.13643">LightGlue</a> <br>
                <a href ="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT</a> <br>
                <a href ="https://he.wikipedia.org/wiki/%D7%90%D7%9C%D7%92%D7%95%D7%A8%D7%99%D7%AA%D7%9D_%D7%A9%D7%9B%D7%9F_%D7%A7%D7%A8%D7%95%D7%91">Knn</a> <br>
                <a href ="https://streamlit.io/">Streamlit.io</a>
            </p>
            <notoc></notoc>
        </div>
    </div>
    <div class="modified">Last modified: Wednesday, 1 May 2024, 10:38 AM</div>
</div>